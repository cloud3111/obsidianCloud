---
banner: "[[pixel-banner-image.png]]"
title: 理解服务器和网络IO模型概念
tags:
  - Server
  - NetworkModels
categories: 编程
date: 2025-09-25T21:15:00
---

	当野花盛开的时候,即使是最灿烂的阳光,也会显得谦逊，只愿静静照耀~
# 理解服务器和网络模型概念
## 服务器
### 按部署方式分
- 物理服务器: 由独立硬件组成, 裸机服务器全年无休
- 虚拟服务器: 在类似于VM虚拟机上部署
- 云服务器: 一种运行在云计算平台上的虚拟服务器, 由物理服务器隔离出来的一个小房间, 如阿里云(ECS)按需付费
- 容器化服务器: 基于Docker部署的隔离式服务器, 轻量启动快
### 按用途分
- Web服务器: 提供网页访问服务
- 应用服务器: 执行实际逻辑, 如Tomcat
- 数据库服务器: 提供存储和数据管理, 如MYSQL, Redis, MongoDB
- 文件服务器: FTP服务器, NAS(网盘)
- 代理服务器: 转发客户端和服务器之间的请求, 如Nginx
- 域名服务器: DNS服务器
### 按协议分
- 在运输层上分为TCP服务器和UDP服务器
- 在应用层分HTTP服务器, 所有的 HTTP 服务器，本质上都是跑在 TCP 服务器之上的
### 服务器的关键指标
- CPU性能：服务器的CPU性能直接影响其计算能力。
- 内存容量：内存容量决定了服务器能够同时处理的任务数量。
- 存储容量：存储容量决定了服务器能够存储的数据量。
- 网络带宽：网络带宽决定了服务器的数据传输速度。
## Socket网络编程
![17588726665161758872665563.png|700x417](https://fastly.jsdelivr.net/gh/cloud3111/cloudWallpaper@main/17588726665161758872665563.png)
### 概念理解
- 文件描述符(**fd: File Description**): Socket 本质上是文件，代表一个进程能打开的最大连接数受操作系统最大打开文件数的限制
- 网络套接字(socket): 由IP和端口构成, 操作系统实现网络通讯
- 一个连接 ≈ 一个 socket ≈ 一个 fd
- 服务器监听`listen()`, 客户端发起`connect()` 共同组成一对Socket对象组
### 一台服务器最大能支持多少连接
- 操作系统会为每个 TCP 连接维护一个 Socket 结构体
	- 本地 IP、端口
	- 对方 IP、端口
	- 协议
- 在操作系统层面, Socket也是文件, 所以连接受最大文件数限制
- 每个 TCP 连接会消耗内核内存, 所以受内存大小限制
- 一个 IP 的端口号范围是 0~65535, 端口占用也有限, 所以受端口限制
## 网络IO模型
- I/O操作都是纯CPU操作, 线程只需要等待或者返回
- IO 操作涉及 用户态/内核态切换，这也是阻塞和非阻塞效率差异的关键
- 传统阻塞 IO 模式每个 TCP 连接都需要一个线程去调用 `read()` 或 `write()`, 线程阻塞在 IO 上，资源消耗大，高并发时线程数爆炸。
- 典型高性能服务器实现方式，如 Netty  -> 单线程可以管理上千个 TCP 连接
	网络 I/O 的处理方式直接影响服务器在高并发下的性能。I/O 操作可分为两个阶段：等待就绪和实际读写。当数据未准备好时，等待阶段不消耗 CPU（内核会挂起线程）；真正的数据读写则需要 CPU 执行，速度非常快。根据是否阻塞以及 I/O 调用方式，可以将 I/O 模型分为以下几类：
- 但是首先要理清一个概念: 连接 -> 线程 -> CPU
![17588783225181758878322314.png](https://fastly.jsdelivr.net/gh/cloud3111/cloudWallpaper@main/17588783225181758878322314.png)
### **BIO**同步阻塞
- 这是最传统的模型，每个连接由一个线程负责。当线程调用 `read()` 或 `write()` 时，如果数据尚未就绪，线程会被阻塞挂起
- 例子: Java的传统的Socket连接/TCP连接(一请求一线程)  `InputStream` / `OutputStream`  
### **NIO**同步非阻塞 -> IO多路复用
- 概念
	- 利用**单个线程监听多个TCP连接**,  客户端发起请求, 服务器用户线程负责执行`read()`和`write()`函数, 如果数据未就绪, 不阻塞线程, 连接直接返回错误, 此时的单线程可以去先去做别的操作, 当某个连接的 `IO` 交互完成, 内核通过 `epoll` 机制唤醒 `Selector`, `Selector` 再把事件分发给其他空闲线程执行回调
- 例子: Redis的单线程IO多路复用
### **AIO**异步非阻塞
- 客户端发起请求, 服务器用户线程调用异步线程由异步线程再去调用CPU执行`read()`和`write()`函数, 然后立即返回结果, 等IO交互完成, 调用回调函数通知
## IO的三种监听方式
### `select`
- 原理：  
    使用 `fd_set`（位图结构，`bit` 数组）保存所有需要监听的 `fd` 可以是已经返回状态的连接, 只需要保存信息, 后续就可以执行回调。调用 `select()` 后，内核会扫描整个 `fd_set`，看哪些 `fd` 就绪，然后返回。
- 特点：
    - 最大 `fd` 数量有限（通常是 1024）。
    - 每次调用 `select` 都要把整个 `fd_set` 从用户态拷贝到内核态，效率低。
- 适用场景：  
    早期跨平台网络编程，但不适合高并发。
![17589568440181758956843173.png|700x295](https://fastly.jsdelivr.net/gh/cloud3111/cloudWallpaper@main/17589568440181758956843173.png)
### `poll`
- 原理：  
    使用 `pollfd` 数组来保存所有`fd`，不再用位图，解决了 `select` 的 1024 限制
- 特点：
    - 理论上可以监听无限多个 `fd`。
    - 但内核依旧要遍历整个数组，效率仍然是 `O(n)`。
    - 每次调用也需要在用户态和内核态之间传递整个数组。
- 适用场景：  
    相比 `select` 更灵活，但在高并发场景依旧不够高效。
![17589582399371758958239061.png](https://fastly.jsdelivr.net/gh/cloud3111/cloudWallpaper@main/17589582399371758958239061.png)
### `epoll`
- 原理：  
    Linux 2.6 引入的高性能 IO 多路复用机制。提供三个核心函数：
    - `epoll_create()`：创建 epoll 实例（红黑树结构存 fd）。
    - `epoll_ctl()`：增删改要监听的 fd。
    - `epoll_wait()`：等待就绪事件，返回已就绪 fd 列表。
- 特点：
    - O(1) 效率：只返回有事件发生的 `fd`，而不是扫描整个集合。
    - 事件驱动：内核用事件回调机制通知，支持 边缘触发（ET） 和 水平触发（LT）。
    - 高并发利器：单机支持百万连接（`Redis`、`Nginx`、`Netty` 等核心依赖 `epoll`）。
- 适用场景：  
    高并发服务器、事件驱动框架
![17589583049381758958304150.png](https://fastly.jsdelivr.net/gh/cloud3111/cloudWallpaper@main/17589583049381758958304150.png)
### 区别
| 特性      | select     | poll       | epoll            |
| ------- | ---------- | ---------- | ---------------- |
| 数据结构    | 位图（fd_set） | 数组（pollfd） | 红黑树 + 就绪链表       |
| fd 限制   | 1024       | 无          | 无                |
| 用户/内核拷贝 | 每次全量拷贝     | 每次全量拷贝     | 只拷贝就绪的 fd        |
| 使用场景    | 早期，小规模并发   | 中等并发       | 高并发（Redis、Nginx） |
