# 2025-05-15
今天进入集合框架和JUC多线程框架的复习

- ArrayList的底层是用数组实现的, 当插入值后超过容器容量时, 自动扩容(extendRatio为当前的1.5倍), 拷贝当前数据到另一个容器(Arrays.copyOf),采用懒汉式的创建对象方式, 当容器长度为0时只会赋值为一个空容器DEFAULTCAPACITY_EMPTY_ARRAY = {};
- 因为扩容消耗资源较大, 所以最好指定其大小
- CopyOnWriteArrayList 就是线程安全版本的 ArrayList。

- HashSet存储的是无序不重复的单值集合, 其实本质是用了hashMap(双值), 只不过值由一个固定的 Object 对象填充

- LinkedList的底层是用双向链表实现的, 是一段不连续的存储空间, 所以不仅可以作为容器, 也可以当做Queue 和 Stack, 

- HashMap的底层实现是用桶数组(链式地址哈希表), 第一个List存储的所有的桶, 第二个List存储的是对应桶链表的具有相同index的所有值(List<List<Node<K, V>>> buckets)
- 通过哈希函数算法分配到不同的桶当中, 将键值对用Node节点存储起来
- 负载因子为0.75f,当前容量超过总容量(默认初始化容量为16)的0.75时, 也就是当前容量超过12时, 触发扩容(扩容因子为2), 把原来的元素重新计算哈希值，放到新的数组中, 丢弃指向原数组的地址(垃圾回收),重新new新容器,  重新初始化(这些桶本身也需要被初始化为空列表)
- 链式地址方式 HashMap内桶数组长度capacity达到64 且节点链表长度达到8时 链表会转换为红黑树以提升查找性能(扩容重构)。 数组 + 链表 + 红黑树 -> 红黑树的查询效率是 O(logn)，比链表的 O(n) 要快
- 如果初始化HashMap，传一个 17的容量，它会怎么处理? 会将容量调整到2的n次方倍以满足哈希算法的需要 - > 为什么是2的幂次方, 一方是因为便于底层的位运算, 另一方面是因为利于均匀分配
- HashMap的哈希算法是通过位运算取模, 而不是简单地取余, 这个 hash 函数是为了让高位也参与到低位计算，提高哈希均匀性，降低冲突概率。int index = (n - 1) & hash
- 哈希表也叫散列表, 都是为了将数据均匀化

- LRU缓存策略: 当新插入的值超过长度的时候进行旧值的删除, 可以只有配置策略(初始容量 负载因子 根据时间排序)

- 写一个实现runnable接口的实现类,然后创建Thread线程,把实现类当做参数传递进去,start()开启线程执行重写的run方法  
- 写一个callable接口的实现类,多加一个FutureTask进行包装, 然后创建Thread线程, 把FutureTask当做参数传递进去,start()开启线程执行重写的call方法, 多了一个回调(FutureTask<String> futureTask = new FutureTask<>(myCallable);)

- Synchronize和ReentrantLock的区别
	- Synchronize 需要锁对象(默认锁对象：this当前Class对象), 不需要手动释放锁,因为 JVM 会确保锁的释放,JVM原生支持它, 是非公平的锁(多人线程竞争锁时不排队), 非公平锁中，线程会先尝试插队（获取锁）
	- ReentrantLock 是由JDK实现的, 是juc包下的, 可公平也可非公平
	- 非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁, 但是不排队被插队的线程可能会死亡
  
- AQS也是java本身实现ReentrantLock的框架(state记录锁状态,cas机制), 它维护了一个共享变量 state( 由 volatile 变量修饰，用于保证多线程之间的可见性；) 和一个线程等待队列(先进先出的双向链表)

- HashTable是线程安全的HashMap
	
- CocurrentHashMap有一个segment数组(大小为16,不可扩容), 且这16个segment都用ReentrantLock修饰保证线程安全, 每一个segment下由数组和链表组成
- segment 数组不能扩容，扩容是 segment 数组某个位置内部的数组 HashEntry<K,V>[ ] 进行扩容，扩容后，容量为原来的 2 倍。
- jdk8的时候将数组和链表升级成了数组链表红黑树, 并且在加锁的时候优先使用cas, 然后才是synchronize锁(只有在有竞争时才会加锁)

- 我们可以利用JUC下的Executors包创建简易或者是复杂的线程池ThreadPoolExecutor
- 线程集合和阻塞队列组成了线程池, 线程集合会不断从阻塞队列中获取任务并执行, 当没有任务了, 就阻塞, 直到下一个任务出现(先进先出)
- 当任务被放入线程池时: 判断当前活动线程数是否小于corePoolSize, 是就使用核心线程(核心线程默认永不销毁)执行任务, 如果大于corePoolSize, 就把任务放入专门执行任务的BlockQueue, 等待被执行, 如果BlockQueue也满了, 但当前活动线程数还没到最大值(当前活动线程数小于maximumPoolSize) → 创建非核心线程来执行任务, 最极端的情况, 当前线程大于maximumPoolSize, 就执行拒绝策略(抛异常, 调用者线程去执行, 直接丢弃, 丢弃最老的任务)
- 创建线程池的两种方式: Executors.new*** 或者是 new ThreadPoolExecutor(…) , 后者让我们更深入理解线程池的配置规则和原理

- scheduledThreadPoolExecutor是继承于threadPoolExecutor的线程池
- 实现方式: 1.new对象 2.工具类的静态方法new  
- 为任务提供延迟或周期执行,使用专门的ScheduledFutureTask来执行周期任务,使用专门的存储队列—DelayedWorkQueue来存储任务

- 重点总结：每一个Thread线程都有自己的局部变量独立副本(ThreadLocalMap), 互不干扰,通过当前Thread对象拿到唯一的ThreadLocalMap, 在这个Map中有很多键值对，key为new出来的ThreadLocal对象，值为要存储的值
- 使用线程池时因为有些核心线程不会在执行完后立即销毁, 因为key是弱引用可被垃圾回收, 但是value是强引用不会被回收, 导致Entry的value里一直有值, 会发生内存泄漏(内存无法被清理), 注意: Entry的key为ThreadLocal对象是弱引用在方法执行完成后被gc, 但是value是强引用无法被gc, 占用内存多了就会发生oom 
- 解决办法: 手动remove
  

- Collections / Arrays  -> 工具类  
- Collectors -> Stream流的收集器    
### Collection单值集合
  
```java  
Iterable  
 └── Collection<T>                     (单值集合的祖宗类)  
      ├── List<T>                      (有序可重复)  
      │    ├── ArrayList               (数组结构)  
      │    ├── LinkedList              (双向链表，也实现了 Queue)      │    └── Vector                  (线程安全，已较少使用)  
      │      ├── Set<T>                       (无序/有序，不可重复)  
      │    ├── HashSet                 (基于哈希表)  
      │    ├── LinkedHashSet           (有序插入 + 哈希表)  
      │    └── TreeSet                 (有序，基于红黑树，SortedSet)  
      │      └── Queue<T>                     (队列/优先队列/双端队列)  
           ├── LinkedList              (双端队列实现 Deque 接口)  
           ├── PriorityQueue           (优先队列，基于堆)  
           └── ArrayDeque              (数组实现的双端队列)  
```  
  
### Map双值集合
  
```java  
Map                (双值集合的祖宗类)    
 ├── HashMap<K,V>              (无序，允许 null 键值，线程不安全)  
 │    └── LinkedHashMap<K,V>   (有序，按插入顺序)  
 ├── TreeMap<K,V>              (有序，基于红黑树)  
 └── Hashtable<K,V>            (线程安全，已过时)  
      └── Properties      (专用于配置文件)  
```