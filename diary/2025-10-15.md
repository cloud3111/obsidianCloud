# 2025-10-15
针对简历中的微服务项目进行自我拷打


- 为什么要使用到微服务
	- 单体服务体积过于庞大, 一旦掉线, 维护困难
	- 服微服务将各个服务像用户, 订单等模块拆分开, 便于多实例部署和业务拓展
- 项目中使用了`springcloud`微服务, 那么微服务有哪几种常见的模块?
	- 服务注册和发现中心: Nacos, 并且支持服务实例的心跳检测
	- 配置中心: Nacos, 统一管理配置文件, 并且支持通过注解实现动态刷新
	- 网关模块: GateWay, 负责请求的鉴权, 限流, 路由等功能
	- 负载均衡组件: LoadBalance, 当一个服务有多个实例时, 使用轮询 权重 随机 最小连接数等各种负载均衡策略来选择具体实例, 达到分流的功能
	- 服务调用: Openfeign, 实现各个微服务之间的互相调用 
	- 限流降级, 熔断降级: Sentinel, 对高并发接口进行限流, 对异常服务进行熔断处理

- 请简单介绍一下你的项目
	- 我做的是一个基于 Spring Cloud 的智慧铁路购票小系统，主要实现了用户登录、验证码校验、车次查询和在线选座购票这些功能。
	- 在实现过程中，我用到了 Redis 做缓存和分布式锁来保证库存更安全，用 RocketMQ 把购票请求做成异步排队避免高并发挤爆系统。
	- 另外我用 Quartz 做了每日车次数据的定时生成，Sa-Token 做登录和权限控制。
	- 整个项目主要是让我熟悉微服务拆分、高并发下的基本处理方式，以及从登录到下单的完整业务流程。


- 异步排队购票下单的核心逻辑是这么做的?
	- 用户选择车次和座位编号下单后, 后端会先判断一张库存表, 这里用做了一个Redis缓存预热,  如果库存不足返回错误, 有库存则生成一个状态为初始化的订单, 并通过RocketMQ去通知要进行当前车次的排队购票
	- 消费消息的核心逻辑
		- 针对当日车次加了一个`Redisson`分布式锁, 并且通过看门狗机制保证在业务执行过程中不会无故释放锁, 在执行完成的finally块中做一个是否为当前线程的锁的判断, 避免锁的误删
		- 对于获取当日车次的订单逻辑上, 如果是一次性获取当日车次的全部订单, 则会有出现内存OOM的风险, 所以最终采用每次分页获取一定数据的订单
		- 然后对拿到的订单做遍历, 前前后后要修改3张表: ticket表 seat表 order表
		- 一个订单可以有多个ticket, 而对于每一个ticket 我们要循环去车次的每个车厢找座位, 
		- 这块逻辑的话我们首先要模拟出当前车厢的所有座位编码, 然后通过偏移值计算出ticket中座位之间的间隔, 方便我们选了一个座位快速定位下一个座位的位置
		-  真正做座位是否已经被购买的逻辑是判断seat的sell字符串 这里面记录每个座位的站与站的购买情况, 之后我们做mapper层的批量更新操作就行


- 如何使用Kaptcha做验证码校验?
	- 首先我们要明白Kaptcha是一个图形验证码校验框架
	- 总体分成2部分
		- 一个是生成验证码, 我们要先把验证码答案把保存在Redis中, 然后让kaptcha根据答案生成图片, 最后以jpg的格式返回给前端
		- 另一部分是验证码检验, 这一部分比较简单, 就是去Redis中判断答案是否一致
	- 至于为什么提高了系统恶意防刷的能力, 这是因为Kaptcha能避免机器人或者脚本恶意频繁调用购票接口

- 你在简历中使用到了saToken, 请简要说一下?
	- saToken是一种提供登陆token认证和权限校验的RBAC安全框架, 相比于`SpringSecurity`, saToken更轻便更加容易上手
	- saToken的核心原理是基于拦截器做token校验, 利用ThreadLocal做用户信息保存, 
	- 而在微服务项目中, 我们可以在网关处注册全局过滤器进行鉴权操作
	- `Sa-Token Session` 是“所有服务共用的用户档案”，放在 Redis，谁拿着 Token 都能访问


- 什么是Quartz, 在你的项目中哪些地方使用到了?
	- 是一个任务调度框架, 也叫定时任务框架
	- 理解4个主要组件
		- Schedule: 调度器, 相当于大脑, 管理Job和Trigger
		- Trigger: 触发器, 是Job任务的触发条件, 有`SimpleTrigger`和`CornTrigger`类型等
		- Job: 底层接口, 实现这个接口的类的对象就可以被调度器进行调度执行
		- JobDetail: 实现 Job 接口，重写 `execute` 方法, 方法里面写自己的任务逻辑
	- 我们可以使用静态工厂的静态builder方法来构建Job和Trigger
		- 对于JobBuilder, 我们可以配置任务的实体实现类, 任务名字和任务组
		- 对于TriggerBuilder, 我们可以配置开始时间, 结束时间, 类型, 触发器名字和触发器组
	- 调用度对于任务和触发器的CRUD
		- 添加任务: addJob(myJob, false);
		- 更新任务: addJob(myJob, true);
		- 更新触发器: scheduler.rescheduleJob(new TriggerKey("oldTrigger", "myGroup"), myTrigger);
		- 取消Trigger触发的任务: scheduler.unscheduleJob(new TriggerKey("myTrigger", "myGroup"));
		- 删除任务: scheduler.deleteJob(new JobKey("myJob", "myGroup"));
		- 获取所有任务组, 循环获得所有任务: scheduler.getJobGroupNames();
		- 后的任务的所有触发器: scheduler.getTriggersOfJob(new JobKey("jobName", "jobGroup"));
	- 相比于spring自带的定时框架,具有更高的自由度,包括任务的开始暂停修改查询删除,还可以进行手动补偿; 更重要的是支持热更新, 无需重启项目
	- 在我的项目中使用到了Quartz在每日凌晨 2:30 自动生成未来 15 天的基础车次数据并写入数据库
	- 其他生产场景中如: 邮件通知、数据清理、日志归档
![17605279584431760527957589.png|696x485](https://fastly.jsdelivr.net/gh/cloud3111/cloudWallpaper@main/17605279584431760527957589.png)


- 为什么使用`SpringCache`, 它与用Redis做缓存有什么区别?
	- `SpringCache`是一个高性能的缓存框架, 本身不是缓存, 只是一个管理框架, 可以接入不同的缓存实现
	- 底层默认使用`SimpleCacheManager`作为缓存管理器, 但是由于底层使用的是`ConcurrentMap`, 又不受框架管理, 所以不支持缓存过期策略, 只能手动删除, 在生产环境中, 一般不直接用默认实现
	- 单体项目推荐使用`CaffeineManager`做缓存管理器, 底层使用的是`ConcurrentLinkedHashMap`, 受框架管理, 支持功能丰富
	- 分布式项目底层使用的就是Redis作为缓存管理器
	- 常用的注解有
		- `@Cacheable`用来做缓存管理器的声明
		- `@CachePut`用来更新缓存
		- `CacheEvict`用来删除缓存